{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This study is based on a survey conducted on 103904 airline passengers. There is limited information on the background of the dataset and how the data was collected. The dataset has been downloaded from the Kaggle website and can be found at the following [link](#ref-scikitdevelopers2024). The project's main goal is to determine the features most strongly correlated with customer satisfaction and to create a model to predict new customer satisfaction levels. Since the response variable, 'satisfaction', is binary, it is a classification problem or a supervised learning task. There are 23 features in total, most of which are categorical in nature. According to the authors of the data's website', it has already been preprocessed for the purpose of classification. However, the dataset will be validated and reprocessed in this notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Transforming the Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70172</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5047</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110028</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24026</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119299</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Gender      Customer Type  Age   Type of Travel     Class  \\\n",
       "0   70172    Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
       "1    5047    Male  disloyal Customer   25  Business travel  Business   \n",
       "2  110028  Female     Loyal Customer   26  Business travel  Business   \n",
       "3   24026  Female     Loyal Customer   25  Business travel  Business   \n",
       "4  119299    Male     Loyal Customer   61  Business travel  Business   \n",
       "\n",
       "   Flight Distance  Inflight wifi service  Departure/Arrival time convenient  \\\n",
       "0              460                      3                                  4   \n",
       "1              235                      3                                  2   \n",
       "2             1142                      2                                  2   \n",
       "3              562                      2                                  5   \n",
       "4              214                      3                                  3   \n",
       "\n",
       "   Ease of Online booking  ...  Inflight entertainment  On-board service  \\\n",
       "0                       3  ...                       5                 4   \n",
       "1                       3  ...                       1                 1   \n",
       "2                       2  ...                       5                 4   \n",
       "3                       5  ...                       2                 2   \n",
       "4                       3  ...                       3                 3   \n",
       "\n",
       "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
       "0                 3                 4                4                 5   \n",
       "1                 5                 3                1                 4   \n",
       "2                 3                 4                4                 4   \n",
       "3                 5                 3                1                 4   \n",
       "4                 4                 4                3                 3   \n",
       "\n",
       "   Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0            5                          25                      18.0   \n",
       "1            1                           1                       6.0   \n",
       "2            5                           0                       0.0   \n",
       "3            2                          11                       9.0   \n",
       "4            3                           0                       0.0   \n",
       "\n",
       "              satisfaction  \n",
       "0  neutral or dissatisfied  \n",
       "1  neutral or dissatisfied  \n",
       "2                satisfied  \n",
       "3  neutral or dissatisfied  \n",
       "4                satisfied  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../Data/Raw/train.csv', index_col = 0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check for missing values reveals that one feature does contain missing values. Other data parameters are also checked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   False\n",
       "Gender                               False\n",
       "Customer Type                        False\n",
       "Age                                  False\n",
       "Type of Travel                       False\n",
       "Class                                False\n",
       "Flight Distance                      False\n",
       "Inflight wifi service                False\n",
       "Departure/Arrival time convenient    False\n",
       "Ease of Online booking               False\n",
       "Gate location                        False\n",
       "Food and drink                       False\n",
       "Online boarding                      False\n",
       "Seat comfort                         False\n",
       "Inflight entertainment               False\n",
       "On-board service                     False\n",
       "Leg room service                     False\n",
       "Baggage handling                     False\n",
       "Checkin service                      False\n",
       "Inflight service                     False\n",
       "Cleanliness                          False\n",
       "Departure Delay in Minutes           False\n",
       "Arrival Delay in Minutes              True\n",
       "satisfaction                         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the data: 310\n"
     ]
    }
   ],
   "source": [
    "# Checking the total amount of missing values:\n",
    "print('Total missing values in the data:', train['Arrival Delay in Minutes'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 103904 entries, 0 to 103903\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   id                                 103904 non-null  int64  \n",
      " 1   Gender                             103904 non-null  object \n",
      " 2   Customer Type                      103904 non-null  object \n",
      " 3   Age                                103904 non-null  int64  \n",
      " 4   Type of Travel                     103904 non-null  object \n",
      " 5   Class                              103904 non-null  object \n",
      " 6   Flight Distance                    103904 non-null  int64  \n",
      " 7   Inflight wifi service              103904 non-null  int64  \n",
      " 8   Departure/Arrival time convenient  103904 non-null  int64  \n",
      " 9   Ease of Online booking             103904 non-null  int64  \n",
      " 10  Gate location                      103904 non-null  int64  \n",
      " 11  Food and drink                     103904 non-null  int64  \n",
      " 12  Online boarding                    103904 non-null  int64  \n",
      " 13  Seat comfort                       103904 non-null  int64  \n",
      " 14  Inflight entertainment             103904 non-null  int64  \n",
      " 15  On-board service                   103904 non-null  int64  \n",
      " 16  Leg room service                   103904 non-null  int64  \n",
      " 17  Baggage handling                   103904 non-null  int64  \n",
      " 18  Checkin service                    103904 non-null  int64  \n",
      " 19  Inflight service                   103904 non-null  int64  \n",
      " 20  Cleanliness                        103904 non-null  int64  \n",
      " 21  Departure Delay in Minutes         103904 non-null  int64  \n",
      " 22  Arrival Delay in Minutes           103594 non-null  float64\n",
      " 23  satisfaction                       103904 non-null  object \n",
      "dtypes: float64(1), int64(18), object(5)\n",
      "memory usage: 19.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Having a quick look at the data types:\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is duplicated: False\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate entries:\n",
    "print('Data is duplicated:', train.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (103904, 24)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the dataset:\n",
    "print('Data shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each feature in the dataset will be evaluated separately. This is the first step in familiarising oneself with the data to ensure every variable is correctly encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique ID values: 103904\n",
      "Total entries in the dataset: 103904\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the `id` column has only unique values:\n",
    "print('Length of unique ID values:', len(train['id'].unique()))\n",
    "print('Total entries in the dataset:', len(train['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m ['Male' 'Female']\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m ['Male', 'Female']\n",
      "Categories (2, object): ['Female', 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Gender'].unique())\n",
    "\n",
    "# Coverting to categorical:\n",
    "train['Gender'] = train['Gender'].astype('category')\n",
    "print('\\n\\033[1mProcessed values:\\033[0m',train['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m ['Loyal Customer' 'disloyal Customer']\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m ['Loyal customer', 'Disloyal customer']\n",
      "Categories (2, object): ['Disloyal customer', 'Loyal customer']\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Customer Type'].unique())\n",
    "\n",
    "# Formatting the column:\n",
    "train['Customer Type'] = train['Customer Type'].str.capitalize()\n",
    "\n",
    "# Coverting to categorical:\n",
    "train['Customer Type'] = train['Customer Type'].astype('category')\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Customer Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUnique values:\u001b[0m [13 25 26 61 47 52 41 20 24 12 53 33 45 38  9 17 43 58 23 57 49 36 22 31\n",
      " 15 35 67 37 40 34 39 50 29 54 21 28 27 69 60 48 59 46 30 66 64 44 51 32\n",
      " 19 42 16 11 62  8 56 68 55 18 65 72 70 63 10  7 14 80 74 71 85 73 76 77\n",
      " 75 79 78]\n",
      "\n",
      "\u001b[1mMinimum Age:\u001b[0m 7\n",
      "\n",
      "\u001b[1mMaximum Age:\u001b[0m 85\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mUnique values:\\033[0m', train['Age'].unique())\n",
    "\n",
    "# Validating the data:\n",
    "print('\\n\\033[1mMinimum Age:\\033[0m', train['Age'].min())\n",
    "print('\\n\\033[1mMaximum Age:\\033[0m', train['Age'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m ['Personal Travel' 'Business travel']\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m ['Personal travel', 'Business travel']\n",
      "Categories (2, object): ['Business travel', 'Personal travel']\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Type of Travel'].unique())\n",
    "\n",
    "# Capitalising the info:\n",
    "train['Type of Travel'] = train['Type of Travel'].str.capitalize()\n",
    "\n",
    "# Coverting to categorical:\n",
    "train['Type of Travel'] = train['Type of Travel'].astype('category')\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Type of Travel'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m ['Eco Plus' 'Business' 'Eco']\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m ['2', '3', '1']\n",
      "Categories (3, object): ['1' < '2' < '3']\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Class'].unique())\n",
    "train['Class'] = train['Class'].str.replace('Eco', '1')\n",
    "train['Class'] = train['Class'].str.replace('1 Plus', '2')\n",
    "train['Class'] = train['Class'].str.replace('Business', '3')\n",
    "\n",
    "# Converting to categorical:\n",
    "train['Class'] = train['Class'].astype('category')\n",
    "train['Class'] = train['Class'].cat.set_categories(new_categories = ['1', '2', '3'], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUnique values:\u001b[0m [ 460  235 1142 ...  974 1479  400]\n",
      "\n",
      "\u001b[1mMinimum Flight Distance:\u001b[0m 31\n",
      "\n",
      "\u001b[1mMaximum Flight Distance:\u001b[0m 4983\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mUnique values:\\033[0m', train['Flight Distance'].unique())\n",
    "\n",
    "# Validating the data:\n",
    "print('\\n\\033[1mMinimum Flight Distance:\\033[0m', train['Flight Distance'].min())\n",
    "print('\\n\\033[1mMaximum Flight Distance:\\033[0m', train['Flight Distance'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [3 2 4 1 5 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [3, 2, 4, 1, 5, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Inflight wifi service'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Inflight wifi service'] = train['Inflight wifi service'].astype('category')\n",
    "train['Inflight wifi service'] = train['Inflight wifi service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Inflight wifi service'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [4 2 5 3 1 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [4, 2, 5, 3, 1, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Departure/Arrival time convenient'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Departure/Arrival time convenient'] = train['Departure/Arrival time convenient'].astype('category')\n",
    "# Rearranging category order:\n",
    "train['Departure/Arrival time convenient'] = train['Departure/Arrival time convenient'].cat.set_categories(new_categories = [1, 2, 3, 4, 5],\n",
    "                                                                                                           ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Departure/Arrival time convenient'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [3 2 5 4 1 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [3, 2, 5, 4, 1, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Ease of Online booking'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Ease of Online booking'] = train['Ease of Online booking'].astype('category')\n",
    "train['Ease of Online booking'] = train['Ease of Online booking'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], \n",
    "                                                                                     ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Ease of Online booking'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [1 3 2 5 4 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [1, 3, 2, 5, 4, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Gate location'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Gate location'] = train['Gate location'].astype('category')\n",
    "train['Gate location'] = train['Gate location'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Gate location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [5 1 2 4 3 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [5, 1, 2, 4, 3, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Food and drink'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Food and drink'] = train['Food and drink'].astype('category')\n",
    "train['Food and drink'] = train['Food and drink'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Food and drink'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [3 5 2 1 4 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [3, 5, 2, 1, 4, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Online boarding'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Online boarding'] = train['Online boarding'].astype('category')\n",
    "train['Online boarding'] = train['Online boarding'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Online boarding'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [5 1 2 3 4 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [5, 1, 2, 3, 4, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Seat comfort'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Seat comfort'] = train['Seat comfort'].astype('category')\n",
    "train['Seat comfort'] = train['Seat comfort'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Seat comfort'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [5 1 2 3 4 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [5, 1, 2, 3, 4, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Inflight entertainment'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Inflight entertainment'] = train['Inflight entertainment'].astype('category')\n",
    "train['Inflight entertainment'] = train['Inflight entertainment'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Inflight entertainment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [4 1 2 3 5 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [4, 1, 2, 3, 5, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['On-board service'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['On-board service'] = train['On-board service'].astype('category')\n",
    "train['On-board service'] = train['On-board service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['On-board service'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [3 5 4 2 1 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [3, 5, 4, 2, 1, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Leg room service'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Leg room service'] = train['Leg room service'].astype('category')\n",
    "train['Leg room service'] = train['Leg room service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Leg room service'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [4 3 5 1 2]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [4, 3, 5, 1, 2]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Baggage handling'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Baggage handling'] = train['Baggage handling'].astype('category')\n",
    "train['Baggage handling'] = train['Baggage handling'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Baggage handling'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [4 1 3 5 2 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [4, 1, 3, 5, 2, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Checkin service'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Checkin service'] = train['Checkin service'].astype('category')\n",
    "train['Checkin service'] = train['Checkin service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Checkin service'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [5 4 3 1 2 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [5, 4, 3, 1, 2, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Inflight service'].unique())\n",
    "\n",
    "# Converting to cordered ategorical:\n",
    "train['Inflight service'] = train['Inflight service'].astype('category')\n",
    "train['Inflight service'] = train['Inflight service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Inflight service'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m [5 1 2 3 4 0]\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m [5, 1, 2, 3, 4, NaN]\n",
      "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['Cleanliness'].unique())\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Cleanliness'] = train['Cleanliness'].astype('category')\n",
    "train['Cleanliness'] = train['Cleanliness'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Cleanliness'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUnique values:\u001b[0m [ 25   1   0  11   9   4  28  43  49   7  17  52  54  27  18  19   3 109\n",
      "  23   8  14  10  51  39  13  30  64  20  45  44  31  81  35  67  22  40\n",
      "  91  21  15  29 105  12 162  24 141   6  34   2  97  16]\n",
      "\n",
      "\u001b[1mDtype:\u001b[0m int64\n",
      "\n",
      "\u001b[1mMinimum Departure Delay in Minutes:\u001b[0m 0\n",
      "\n",
      "\u001b[1mMaximum Departure Delay in Minutes:\u001b[0m 1592\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mUnique values:\\033[0m', train['Departure Delay in Minutes'].unique()[0:50])\n",
    "\n",
    "# Checking column dtype:\n",
    "print('\\n\\033[1mDtype:\\033[0m', train['Departure Delay in Minutes'].dtype)\n",
    "\n",
    "# Validating data:\n",
    "print('\\n\\033[1mMinimum Departure Delay in Minutes:\\033[0m', train['Departure Delay in Minutes'].min())\n",
    "print('\\n\\033[1mMaximum Departure Delay in Minutes:\\033[0m', train['Departure Delay in Minutes'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUnique values:\u001b[0m [ 18.   6.   0.   9.  23.   8.  35.  51.  10.   5.   4.  29.  44.  28.\n",
      "  12. 120.  24.   1.  20.  31.  15.  48.  26.  49.   2.  37.  50.   3.\n",
      "  19.  72.  11.  34.  62.  27.  52.  13.  82.  30.  16.   7. 122. 179.\n",
      " 125.  17.  nan  89. 101.  14.  61.  32.  33.  41. 191. 138.  53.  22.\n",
      "  57.  65.  76. 107.  92. 164.  21.  40.  55. 185.  63.  77.  86.  91.\n",
      " 100.  54.  36.  70. 139.  67. 163. 128. 180.  93. 121.  45. 105. 126.\n",
      "  56.  73. 212.  88. 241. 172. 175. 111.  99.  25.  42. 226.  46. 131.\n",
      " 260.  69.]\n",
      "\n",
      "\u001b[1mDtype:\u001b[0m float64\n",
      "\n",
      "\u001b[1mMinimum Departure Delay in Minutes:\u001b[0m 0.0\n",
      "\n",
      "\u001b[1mMaximum Departure Delay in Minutes:\u001b[0m 1584.0\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mUnique values:\\033[0m', train['Arrival Delay in Minutes'].unique()[0:100])\n",
    "\n",
    "# Checking column dtype:\n",
    "print('\\n\\033[1mDtype:\\033[0m', train['Arrival Delay in Minutes'].dtype)\n",
    "\n",
    "# Validating data:\n",
    "print('\\n\\033[1mMinimum Departure Delay in Minutes:\\033[0m', train['Arrival Delay in Minutes'].min())\n",
    "print('\\n\\033[1mMaximum Departure Delay in Minutes:\\033[0m', train['Arrival Delay in Minutes'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal values:\u001b[0m ['neutral or dissatisfied' 'satisfied']\n",
      "\n",
      "\u001b[1mProcessed values:\u001b[0m ['neutral or dissatisfied', 'satisfied']\n",
      "Categories (2, object): ['neutral or dissatisfied' < 'satisfied']\n"
     ]
    }
   ],
   "source": [
    "# Unique column values:\n",
    "print('\\033[1mOriginal values:\\033[0m', train['satisfaction'].unique())\n",
    "\n",
    "# Formatting column name:\n",
    "train = train.rename(columns = {'satisfaction': 'Satisfaction'})\n",
    "train['Satisfaction'].unique()\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Satisfaction'] = train['Satisfaction'].astype('category')\n",
    "train['Satisfaction'] = train['Satisfaction'].cat.set_categories(new_categories = ['neutral or dissatisfied', 'satisfied'], ordered = True)\n",
    "\n",
    "# Unique column values:\n",
    "print('\\n\\033[1mProcessed values:\\033[0m', train['Satisfaction'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating column name:\n",
    "train = train.rename(columns = {'Inflight wifi service': 'Inflight Wifi Service', 'Departure/Arrival time convenient': 'Departure/Arrival Time Convenient',\n",
    "                                'Ease of Online booking': 'Ease of Online Booking', 'Gate location': 'Gate Location', \n",
    "                                'Food and drink': 'Food and Drink', 'Online boarding': 'Online Boarding', 'Seat comfort': 'Seat Comfort',\n",
    "                                'Inflight entertainment': 'Inflight Entertainment', 'On-board service': 'On-board Service', 'Leg room service': 'Leg Room Service',\n",
    "                                'Baggage handling': 'Baggage Handling', 'Checkin service': 'Checkin Service', 'Inflight service': 'Inflight Service'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how many NaNs were created when cleaning the data and setting correct ordered category values. This will be further analysed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      0\n",
       "Gender                                  0\n",
       "Customer Type                           0\n",
       "Age                                     0\n",
       "Type of Travel                          0\n",
       "Class                                   0\n",
       "Flight Distance                         0\n",
       "Inflight Wifi Service                3103\n",
       "Departure/Arrival Time Convenient    5300\n",
       "Ease of Online Booking               4487\n",
       "Gate Location                           1\n",
       "Food and Drink                        107\n",
       "Online Boarding                      2428\n",
       "Seat Comfort                            1\n",
       "Inflight Entertainment                 14\n",
       "On-board Service                        3\n",
       "Leg Room Service                      472\n",
       "Baggage Handling                        0\n",
       "Checkin Service                         1\n",
       "Inflight Service                        3\n",
       "Cleanliness                            12\n",
       "Departure Delay in Minutes              0\n",
       "Arrival Delay in Minutes              310\n",
       "Satisfaction                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values:\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to further analysis, this version of the dataset will be stored for use in the `exploratory_data_analysis` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train.to_pickle('../Data/Preprocessed/train_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the response variable must be formatted in a numeric format. Using a dictionary, the 'neutral or dissatisfied' category is converted to '1', and the 'satisfied' category is converted to '2'. Since 'neutral or dissatisfied' is less than 'satisfied', the category is set to ‘ordered’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/2qtxqpxj07g0pvc7h463fm_w0000gn/T/ipykernel_92608/1028444235.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['Satisfaction'] = train['Satisfaction'].replace(change).infer_objects(copy=False)\n",
      "/var/folders/1z/2qtxqpxj07g0pvc7h463fm_w0000gn/T/ipykernel_92608/1028444235.py:5: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  train['Satisfaction'] = train['Satisfaction'].replace(change).infer_objects(copy=False)\n"
     ]
    }
   ],
   "source": [
    "# Defining the variable transformation needed:\n",
    "change = {'satisfied': 2, 'neutral or dissatisfied': 1}\n",
    "\n",
    "# Performing the transformation and converting to integer:\n",
    "train['Satisfaction'] = train['Satisfaction'].replace(change).infer_objects(copy=False)\n",
    "train['Satisfaction'] = train['Satisfaction'].astype('int')\n",
    "\n",
    "# Converting to ordered categorical:\n",
    "train['Satisfaction'] = train['Satisfaction'].astype('category')\n",
    "train['Satisfaction'] = train['Satisfaction'].cat.set_categories(new_categories = [1, 2], ordered = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the dataset will also be saved for use in the `exploratory_data_analysis` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train.to_pickle('../Data/Preprocessed/train_preprocessed_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement machine learning models, nominal categorical variables must also be formatted into numerical. The ideal way to do this is through Panda's `get_dummies` function. This function creates extra columns with dummy variables corresponding to the total number of categories in the variables of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dummies for the nominal variables:\n",
    "train = pd.get_dummies(train, columns = ['Gender', 'Customer Type', 'Type of Travel'], prefix = 'Dummy', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train.to_pickle('../Data/Preprocessed/train_preprocessed_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset description mentions that many of the categorical variables have a 'Not Applicable' category. By taking a closer look at these values (see below), it can be seen that often when a feature has NaNs, other features also have NaNs. However, the pattern is inconsistent; for example, the dataset below has been filtered for NaN values in `Ease of Online Booking`. For these entries, the values of `Departure/Arrival Time Convenient` and `Inflight Wifi Service` are only sometimes missing. For this reason, it can be concluded that the data seems to be **Missing At Random** (MAR). \n",
    "\n",
    "This is quite a common problem in survey data. Many survey respondents may skip over questions because they did not use the service; others simply did not understand the question and preferred to mark the answer as 'Not Applicable'. The latter could easily apply to elder individuals [Hannah Igboke, 2024](#ref-Igkobe2024).\n",
    "\n",
    "If the data is missing, then a good strategy would be to use imputation methods to 'extrapolate' the missing values from the available data. If, on the other hand, the data is actually 'Not Applicable’, then dropping these entries or accepting them as such might be a better strategy. Both situations will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight Wifi Service</th>\n",
       "      <th>Departure/Arrival Time Convenient</th>\n",
       "      <th>Ease of Online Booking</th>\n",
       "      <th>Gate Location</th>\n",
       "      <th>Food and Drink</th>\n",
       "      <th>Online Boarding</th>\n",
       "      <th>...</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Dummy_Female</th>\n",
       "      <th>Dummy_Male</th>\n",
       "      <th>Dummy_Disloyal customer</th>\n",
       "      <th>Dummy_Loyal customer</th>\n",
       "      <th>Dummy_Business travel</th>\n",
       "      <th>Dummy_Personal travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14849</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>78972</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>2496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>76392</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>73604</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>104623</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103683</th>\n",
       "      <td>17529</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103700</th>\n",
       "      <td>50815</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103728</th>\n",
       "      <td>15861</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103814</th>\n",
       "      <td>70449</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103858</th>\n",
       "      <td>69123</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4487 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Age Class  Flight Distance Inflight Wifi Service  \\\n",
       "42       14849   41     3              296                   NaN   \n",
       "56       78972   57     3             2496                   NaN   \n",
       "90       76392   60     1              931                   NaN   \n",
       "148      73604   55     3             3634                   NaN   \n",
       "162     104623   20     1              861                   NaN   \n",
       "...        ...  ...   ...              ...                   ...   \n",
       "103683   17529   24     2              241                   NaN   \n",
       "103700   50815   24     1              266                     2   \n",
       "103728   15861   49     3             3578                   NaN   \n",
       "103814   70449   64     1              187                     2   \n",
       "103858   69123   51     1             1598                   NaN   \n",
       "\n",
       "       Departure/Arrival Time Convenient Ease of Online Booking Gate Location  \\\n",
       "42                                   NaN                    NaN             3   \n",
       "56                                   NaN                    NaN             1   \n",
       "90                                     5                    NaN             3   \n",
       "148                                    4                    NaN             4   \n",
       "162                                  NaN                    NaN             5   \n",
       "...                                  ...                    ...           ...   \n",
       "103683                                 2                    NaN             3   \n",
       "103700                               NaN                    NaN             5   \n",
       "103728                               NaN                    NaN             3   \n",
       "103814                                 4                    NaN             2   \n",
       "103858                                 5                    NaN             2   \n",
       "\n",
       "       Food and Drink Online Boarding  ... Cleanliness  \\\n",
       "42                  2               5  ...           3   \n",
       "56                  3               4  ...           5   \n",
       "90                  4             NaN  ...           4   \n",
       "148                 4               5  ...           3   \n",
       "162                 2             NaN  ...           2   \n",
       "...               ...             ...  ...         ...   \n",
       "103683              2             NaN  ...           2   \n",
       "103700              1             NaN  ...           1   \n",
       "103728              2               1  ...           3   \n",
       "103814              3             NaN  ...           3   \n",
       "103858              3             NaN  ...           3   \n",
       "\n",
       "       Departure Delay in Minutes Arrival Delay in Minutes Satisfaction  \\\n",
       "42                              0                      0.0            2   \n",
       "56                              0                      5.0            2   \n",
       "90                              0                      0.0            2   \n",
       "148                             0                      0.0            2   \n",
       "162                             0                      0.0            2   \n",
       "...                           ...                      ...          ...   \n",
       "103683                          1                      0.0            2   \n",
       "103700                          0                      0.0            1   \n",
       "103728                         65                     95.0            2   \n",
       "103814                          0                      0.0            1   \n",
       "103858                          1                      1.0            2   \n",
       "\n",
       "       Dummy_Female Dummy_Male Dummy_Disloyal customer Dummy_Loyal customer  \\\n",
       "42                0          1                       0                    1   \n",
       "56                1          0                       0                    1   \n",
       "90                0          1                       0                    1   \n",
       "148               1          0                       0                    1   \n",
       "162               0          1                       1                    0   \n",
       "...             ...        ...                     ...                  ...   \n",
       "103683            1          0                       1                    0   \n",
       "103700            0          1                       0                    1   \n",
       "103728            1          0                       0                    1   \n",
       "103814            0          1                       0                    1   \n",
       "103858            0          1                       0                    1   \n",
       "\n",
       "        Dummy_Business travel  Dummy_Personal travel  \n",
       "42                          1                      0  \n",
       "56                          1                      0  \n",
       "90                          0                      1  \n",
       "148                         1                      0  \n",
       "162                         1                      0  \n",
       "...                       ...                    ...  \n",
       "103683                      1                      0  \n",
       "103700                      0                      1  \n",
       "103728                      1                      0  \n",
       "103814                      0                      1  \n",
       "103858                      0                      1  \n",
       "\n",
       "[4487 rows x 27 columns]"
      ]
     },
     "execution_count": 1906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Ease of Online Booking'].isna() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's IterativeImputer runs a regression for each variable with a ‘Not Applicable’ categorical entry and uses all other features to impute the ‘missing’ value. The model is then trained on the new data, and the process is repeated several times [(Scikit-learn developers, 2024)](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the saved file: \n",
    "train = pd.read_pickle('../Data/Preprocessed/train_preprocessed_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the IterativeImputer will be instantiated. Since one numeric feature has missing values, the `initial_strategy` will be set to the 'mean'. A `random_state` will also be set to ensure reproducibility. The `max_iter` parameter is increased to 20 (the default is 10) to obtain good results. The instantiated imputer is then used to impute the dataset's 'missing' values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the IterativeImputer:\n",
    "imputer = IterativeImputer(initial_strategy='mean', random_state = 42, max_iter = 20)\n",
    "\n",
    "# Imputing the data with the instantiated imputer:\n",
    "imputed_data = imputer.fit_transform(train)\n",
    "train_imputed_iterative = pd.DataFrame(imputed_data, columns = train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset is saved for further evaluation in the `model_training_and_evaluation` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train_imputed_iterative.to_pickle('../Data/Preprocessed/train_imputed_iterative.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN imputation method will also be attempted. This method imputes the feature's missing values based on the *k*-nearest neighbours using the whole dataset. The neighbours are determined using Euclidean distance by default. This method requires all numerical values to be scaled in order to avoid imputation bias [Kyaw Saw Htoon, 2020](#ref-htoon2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the first preprocessed dataset:\n",
    "train = pd.read_pickle('../Data/Preprocessed/train_preprocessed_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, numerical data will be normalised using Scikit-learns' MinMaxScaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the KNN imputer is instantiated with 18000 neighbours. Although it is common practice to set the `n_neighbors` parameter of the KNNimputer to the square root of the total number of observations, `n_neighbors = sqrt(n_obs)`, that is $k = 322$. However, after some manual hyperparameter tuning, a larger value of $k$ provides better results. This makes sense since the dataset is quite large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the KNN imputer:\n",
    "imputer_knn = KNNImputer(n_neighbors=18000)\n",
    "\n",
    "# Imputing the missing values:\n",
    "imputed_data_knn = imputer_knn.fit_transform(train)\n",
    "train_imputed_knn = pd.DataFrame(imputed_data_knn, columns = train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the new data set for further analysis in the `model_training_and_evaluation` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train_imputed_knn.to_pickle('../Data/Preprocessed/train_imputed_knn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropna with Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../Data/Preprocessed/train_preprocessed_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the entries with 'Non Applicable' categories are considered meaningless for the analysis and are dropped. Entries where NaN values are less than 5% of the data will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for dropping NaNs: 5195\n",
      "\n",
      "Columns where NaN entries can be dropped:\n",
      "['id',\n",
      " 'Age',\n",
      " 'Class',\n",
      " 'Flight Distance',\n",
      " 'Inflight Wifi Service',\n",
      " 'Ease of Online Booking',\n",
      " 'Gate Location',\n",
      " 'Food and Drink',\n",
      " 'Online Boarding',\n",
      " 'Seat Comfort',\n",
      " 'Inflight Entertainment',\n",
      " 'On-board Service',\n",
      " 'Leg Room Service',\n",
      " 'Baggage Handling',\n",
      " 'Checkin Service',\n",
      " 'Inflight Service',\n",
      " 'Cleanliness',\n",
      " 'Departure Delay in Minutes',\n",
      " 'Arrival Delay in Minutes',\n",
      " 'Satisfaction',\n",
      " 'Dummy_Female',\n",
      " 'Dummy_Male',\n",
      " 'Dummy_Disloyal customer',\n",
      " 'Dummy_Loyal customer',\n",
      " 'Dummy_Business travel',\n",
      " 'Dummy_Personal travel']\n",
      "\n",
      "Columns where NaNs need to be imputed:\n",
      "['Departure/Arrival Time Convenient']\n"
     ]
    }
   ],
   "source": [
    "# Establishing a threshold in accordance with the dataset size for the deletion of NaNs:\n",
    "threshold = len(train)*0.05\n",
    "print('Threshold for dropping NaNs:', round(threshold))\n",
    "\n",
    "# Identifying the columns for which NaNs can be dropped:\n",
    "columns_to_drop = train.columns[train.isna().sum() <= threshold]\n",
    "print('\\nColumns where NaN entries can be dropped:')\n",
    "pprint(list(columns_to_drop))\n",
    "\n",
    "# Identifying the columns for which NaNs should be imputed:\n",
    "cols_to_impute = train.columns[train.isna().sum() > threshold]\n",
    "print('\\nColumns where NaNs need to be imputed:')\n",
    "pprint(list(cols_to_impute))\n",
    "\n",
    "# Dropping columns with small amounts of NaNs:\n",
    "train = train.dropna(subset=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the set of features where NaNs can be dropped includes the numeric variable 'Arrival Delay in Minutes'. For all other columns where there are more missing values than the established threshold the NaNs will be imputed using the feature's mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each column to impute NaNs with the mode:\n",
    "for col in cols_to_impute:\n",
    "    mode_value = train[col].mode()\n",
    "    if not mode_value.empty:\n",
    "        train[col] = train[col].fillna(mode_value.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the new data set for further analysis in the `model_training_and_evaluation` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the first preprocessed dataset to pickle to preserve data type information:\n",
    "# train.to_pickle('../Data/Preprocessed/train_preprocessed_dropna_mode.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Extra Category for 'Non-Applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../Data/Preprocessed/train_preprocessed_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last attempt at dealing with the NaN values will be to create a separate numeric category for such entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the categorical features with NaN values:\n",
    "non_applicable_category = ['Inflight Wifi Service', 'Departure/Arrival Time Convenient', 'Ease of Online Booking', 'Gate Location', 'Food and Drink', 'Online Boarding',\n",
    "                           'Seat Comfort', 'Inflight Entertainment', 'On-board Service', 'Leg Room Service', 'Checkin Service', 'Inflight Service', 'Cleanliness']\n",
    "\n",
    "# Setting new category values for the defined features:\n",
    "for feature in non_applicable_category:\n",
    "    train[feature] = train[feature].astype('category')\n",
    "    train[feature] = train[feature].cat.set_categories(new_categories = [0, 1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "# Replacing the NaNs with 0:\n",
    "assigning = {np.nan: 0}\n",
    "\n",
    "for feature in non_applicable_category:\n",
    "    train[feature] = train[feature].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   False\n",
       "Age                                  False\n",
       "Class                                False\n",
       "Flight Distance                      False\n",
       "Inflight Wifi Service                False\n",
       "Departure/Arrival Time Convenient    False\n",
       "Ease of Online Booking               False\n",
       "Gate Location                        False\n",
       "Food and Drink                       False\n",
       "Online Boarding                      False\n",
       "Seat Comfort                         False\n",
       "Inflight Entertainment               False\n",
       "On-board Service                     False\n",
       "Leg Room Service                     False\n",
       "Baggage Handling                     False\n",
       "Checkin Service                      False\n",
       "Inflight Service                     False\n",
       "Cleanliness                          False\n",
       "Departure Delay in Minutes           False\n",
       "Arrival Delay in Minutes              True\n",
       "Satisfaction                         False\n",
       "Dummy_Female                         False\n",
       "Dummy_Male                           False\n",
       "Dummy_Disloyal customer              False\n",
       "Dummy_Loyal customer                 False\n",
       "Dummy_Business travel                False\n",
       "Dummy_Personal travel                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 1920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the remaining missing values:\n",
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last feature with missing values (numeric) will be imputed using the iterative imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the IterativeImputer:\n",
    "imputer = IterativeImputer(initial_strategy='mean', random_state = 42, max_iter = 20)\n",
    "\n",
    "# Imputing the missing values:\n",
    "non_applicable_data = imputer.fit_transform(train)\n",
    "non_applicable_imputed = pd.DataFrame(non_applicable_data, columns = train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the new data set for further analysis in the `model_training_and_evaluation` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the non-applicable dataset to pickle:\n",
    "# non_applicable_imputed.to_pickle('../Data/Preprocessed/non_applicable_imputed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlining for Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the previous data preprocessing was quite substantial, a function will be defined to streamline this process for the test data set and in the eventuality if more data becomes available. The last method (that is, 'Creating an Extra Category for 'Non-Applicable') will be used to create this function, since it was the method with the best accuracy on the test set (see `model_training_and_evaluation` for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "\n",
    "    # Checking for duplicate entries:\n",
    "    print(f'\\nData is duplicated:', data.duplicated().any())\n",
    "\n",
    "    # Checking whether the `id` column has only unique values:\n",
    "    print(f'\\nLength of unique ID values:', len(data['id'].unique()))\n",
    "\n",
    "    # Convert 'Gender' to categorical:\n",
    "    data['Gender'] = data['Gender'].astype('category')\n",
    "\n",
    "    # Format 'Customer Type' column:\n",
    "    data['Customer Type'] = data['Customer Type'].str.capitalize()\n",
    "    data['Customer Type'] = data['Customer Type'].astype('category')\n",
    "\n",
    "    # Validating the 'Age' column:\n",
    "    print('\\nMinimum Age:', data['Age'].min())\n",
    "    print('Maximum Age:', data['Age'].max())\n",
    "\n",
    "    # Format the 'Type of Travel' column:\n",
    "    data['Type of Travel'] = data['Type of Travel'].str.capitalize()\n",
    "    data['Type of Travel'] = data['Type of Travel'].astype('category')\n",
    "\n",
    "    # Format the 'Class' column:\n",
    "    data['Class'] = data['Class'].str.replace('Eco', '1')\n",
    "    data['Class'] = data['Class'].str.replace('1 Plus', '2')\n",
    "    data['Class'] = data['Class'].str.replace('Business', '3')\n",
    "    data['Class'] = data['Class'].astype('category')\n",
    "    data['Class'] = data['Class'].cat.set_categories(new_categories = ['1', '2', '3'], ordered = True)\n",
    "\n",
    "    # Validate the 'Flight Distance' column:\n",
    "    print('\\nMinimum Flight Distance:', data['Flight Distance'].min())\n",
    "    print('Maximum Flight Distance:', data['Flight Distance'].max())\n",
    "\n",
    "    # Format the 'Inflight wifi service' column:\n",
    "    data['Inflight wifi service'] = data['Inflight wifi service'].astype('category')\n",
    "    data['Inflight wifi service'] = data['Inflight wifi service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Departure/Arrival time convenient' column:\n",
    "    data['Departure/Arrival time convenient'] = data['Departure/Arrival time convenient'].astype('category')\n",
    "    data['Departure/Arrival time convenient'] = data['Departure/Arrival time convenient'].cat.set_categories(new_categories = [1, 2, 3, 4, 5],\n",
    "                                                                                                           ordered = True)\n",
    "    \n",
    "    # Format the 'Ease of Online booking' column:\n",
    "    data['Ease of Online booking'] = data['Ease of Online booking'].astype('category')\n",
    "    data['Ease of Online booking'] = data['Ease of Online booking'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], \n",
    "                                                                                     ordered = True)\n",
    "    \n",
    "    # Format the 'Gate location' column:\n",
    "    data['Gate location'] = data['Gate location'].astype('category')\n",
    "    data['Gate location'] = data['Gate location'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Food and drink' column:\n",
    "    data['Food and drink'] = data['Food and drink'].astype('category')\n",
    "    data['Food and drink'] = data['Food and drink'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Online boarding' column:\n",
    "    data['Online boarding'] = data['Online boarding'].astype('category')\n",
    "    data['Online boarding'] = data['Online boarding'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Seat comfort' column:\n",
    "    data['Seat comfort'] = data['Seat comfort'].astype('category')\n",
    "    data['Seat comfort'] = data['Seat comfort'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Inflight entertainment' column:\n",
    "    data['Inflight entertainment'] = data['Inflight entertainment'].astype('category')\n",
    "    data['Inflight entertainment'] = data['Inflight entertainment'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'On-board service' column:\n",
    "    data['On-board service'] = data['On-board service'].astype('category')\n",
    "    data['On-board service'] = data['On-board service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Leg room service' column:\n",
    "    data['Leg room service'] = data['Leg room service'].astype('category')\n",
    "    data['Leg room service'] = data['Leg room service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Baggage handling' column:\n",
    "    data['Baggage handling'] = data['Baggage handling'].astype('category')\n",
    "    data['Baggage handling'] = data['Baggage handling'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Checkin service' column:\n",
    "    data['Checkin service'] = data['Checkin service'].astype('category')\n",
    "    data['Checkin service'] = data['Checkin service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Inflight service' column:\n",
    "    data['Inflight service'] = data['Inflight service'].astype('category')\n",
    "    data['Inflight service'] = data['Inflight service'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Format the 'Cleanliness' column:\n",
    "    data['Cleanliness'] = data['Cleanliness'].astype('category')\n",
    "    data['Cleanliness'] = data['Cleanliness'].cat.set_categories(new_categories = [1, 2, 3, 4, 5], ordered = True)\n",
    "\n",
    "    # Validate the 'Departure Delay in Minutes' column:\n",
    "    print('\\nMinimum Departure Delay in Minutes:', data['Departure Delay in Minutes'].min())\n",
    "    print('Maximum Departure Delay in Minutes:',data['Departure Delay in Minutes'].max())\n",
    "\n",
    "    # Validate the 'Arrival Delay in Minutes' column:\n",
    "    print('\\nMinimum Arrival Delay in Minutes:', data['Arrival Delay in Minutes'].min())\n",
    "    print('Maximum Arrival Delay in Minutes:', data['Arrival Delay in Minutes'].max())\n",
    "\n",
    "    # One-hot encoding nominal features:\n",
    "    data = pd.get_dummies(data, columns = ['Gender', 'Customer Type', 'Type of Travel'], prefix = 'Dummy', dtype = int)\n",
    "\n",
    "    # Format the 'satisfaction' column:\n",
    "    data = data.rename(columns = {'satisfaction': 'Satisfaction'})\n",
    "    # Defining the variable transformation needed:\n",
    "    change = {'satisfied': 2, 'neutral or dissatisfied': 1}\n",
    "    # Performing the transformation and converting to integer:\n",
    "    data['Satisfaction'] = data['Satisfaction'].replace(change).infer_objects(copy=False)\n",
    "    data['Satisfaction'] = data['Satisfaction'].astype('int')\n",
    "    # Converting to ordered categorical:\n",
    "    data['Satisfaction'] = data['Satisfaction'].astype('category')\n",
    "    data['Satisfaction'] = data['Satisfaction'].cat.set_categories(new_categories = [1, 2], ordered = True)\n",
    "\n",
    "    # Format other column name:\n",
    "    data = data.rename(columns = {'Inflight wifi service': 'Inflight Wifi Service', 'Departure/Arrival time convenient': 'Departure/Arrival Time Convenient',\n",
    "                                'Ease of Online booking': 'Ease of Online Booking', 'Gate location': 'Gate Location', \n",
    "                                'Food and drink': 'Food and Drink', 'Online boarding': 'Online Boarding', 'Seat comfort': 'Seat Comfort',\n",
    "                                'Inflight entertainment': 'Inflight Entertainment', 'On-board service': 'On-board Service', 'Leg room service': 'Leg Room Service',\n",
    "                                'Baggage handling': 'Baggage Handling', 'Checkin service': 'Checkin Service', 'Inflight service': 'Inflight Service'})\n",
    "    \n",
    "    def resolve_nans(df):\n",
    "        # Defining the categorical features where NaNs could be located:\n",
    "        non_applicable_category = ['Inflight Wifi Service', 'Departure/Arrival Time Convenient', 'Ease of Online Booking', 'Gate Location', \n",
    "                                   'Food and Drink', 'Online Boarding', 'Seat Comfort', 'Inflight Entertainment', 'On-board Service', \n",
    "                                   'Leg Room Service', 'Baggage Handling', 'Checkin Service', 'Inflight Service', 'Cleanliness']\n",
    "\n",
    "        # Setting new category values for the defined features:\n",
    "        for feature in non_applicable_category:\n",
    "            df[feature] = df[feature].astype('category')\n",
    "            df[feature] = df[feature].cat.set_categories(new_categories = [0, 1, 2, 3, 4, 5], ordered = True)\n",
    "        \n",
    "        # Replacing the NaNs with 0:\n",
    "        assigning = {np.nan: 0}\n",
    "        for feature in non_applicable_category:\n",
    "            df[feature] = df[feature].fillna(0)\n",
    "        \n",
    "        # Instantiating the IterativeImputer:\n",
    "        imputer = IterativeImputer(initial_strategy='mean', random_state = 42, max_iter = 20)\n",
    "\n",
    "        # Imputing the missing values for numeric data:\n",
    "        numeric_data = imputer.fit_transform(df)\n",
    "        numeric_data_imputed = pd.DataFrame(numeric_data, columns = data.columns)\n",
    "\n",
    "        return numeric_data_imputed\n",
    "    \n",
    "    data = resolve_nans(data)\n",
    "    # Checking the shape of the dataset:\n",
    "    print('\\nData shape:', data.shape)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Transforming the Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process is performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data set:\n",
    "test = pd.read_csv('../Data/Raw/test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data is duplicated: False\n",
      "\n",
      "Length of unique ID values: 25976\n",
      "\n",
      "Minimum Age: 7\n",
      "Maximum Age: 85\n",
      "\n",
      "Minimum Flight Distance: 31\n",
      "Maximum Flight Distance: 4983\n",
      "\n",
      "Minimum Departure Delay in Minutes: 0\n",
      "Maximum Departure Delay in Minutes: 1128\n",
      "\n",
      "Minimum Arrival Delay in Minutes: 0.0\n",
      "Maximum Arrival Delay in Minutes: 1115.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/2qtxqpxj07g0pvc7h463fm_w0000gn/T/ipykernel_92608/3260739351.py:109: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Satisfaction'] = data['Satisfaction'].replace(change).infer_objects(copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (25976, 27)\n"
     ]
    }
   ],
   "source": [
    "# Using the created function to process the test set:\n",
    "test = data_preprocessing(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets are now ready. The next step is to perform an Exploratory Data Analysis on the train set. Please go to the `exploratory_data_analysis` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the preprocessed test dataset to pickle:\n",
    "# test.to_pickle('../Data/Preprocessed/test_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"ref-scikitdevelopers2024\"></a>Scikit-learn developers, IterativeImputer, *Scikit-Learn*, 2024. [Link](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)\n",
    "2. <a id=\"ref-htoon2020\"></a>Kyaw Saw Htoon, A Guide to KNN Imputation, *Medium*, 3 July 2020. [Link](https://medium.com/@kyawsawhtoon/a-guide-to-knn-imputation-95e2dc496e)\n",
    "3. <a id=\"ref-Igkobe2024\"></a>Hannah Igboke, Iterative Imputer for Missing values in Machine Learning, *Medium*, 10 June 2024. [Link](https://medium.com/learning-data/iterative-imputer-for-missing-values-in-machine-learning-32bd8b5b697a#:~:text=Statistical%20models%20used%20in%20iterative%20imputation&text=DecisionTreeRegressor%3A%20non%2Dlinear%20regression%20models,no%20need%20for%20feature%20scaling.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
